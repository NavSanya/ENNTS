{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "682b2e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_formats = ['svg']\n",
    "\n",
    "import random\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm # Colormaps\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "np.random.seed(42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "74b31a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSets:\n",
    "    \"\"\"\n",
    "    munClasses->specifies the number of classes the grid should have\n",
    "    minRange->gives the lower limit of the classes and the points should be in\n",
    "    maxRange->gives the upper limit of the classes and the points should be in\n",
    "    \"\"\"\n",
    "    def __init__(myobject, numClasses, numpoints, minRange, maxRange):\n",
    "        myobject.numClasses = numClasses\n",
    "        myobject.numpoints = numpoints\n",
    "        myobject.minRange = minRange\n",
    "        myobject.maxRange = maxRange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "5433baf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def multidimential_gauss(x, d, mean, covariance):\n",
    "        \"\"\"pdf of the multivariate normal distribution.\"\"\"\n",
    "        x_m = x - mean\n",
    "        return (1. / (np.sqrt((2 * np.pi)**d * np.linalg.det(covariance))) * \n",
    "                np.exp(-(np.linalg.solve(covariance, x_m).T.dot(x_m)) / 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e85b5aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def generate_surface(mean, covariance, d):\n",
    "        \"\"\"Helper function to generate density surface.\"\"\"\n",
    "        nb_of_x = 50 # grid size\n",
    "        x1s = np.linspace(-10, 10, num=nb_of_x)\n",
    "        x2s = np.linspace(-10, 10, num=nb_of_x)\n",
    "        x1, x2 = np.meshgrid(x1s, x2s) # Generate grid\n",
    "        pdf = np.zeros((nb_of_x, nb_of_x))\n",
    "        # Fill the cost matrix for each combination of weights\n",
    "        for i in range(nb_of_x):\n",
    "            for j in range(nb_of_x):\n",
    "                pdf[i,j] = multidimential_gauss(\n",
    "                    np.matrix([[x1[i,j]], [x2[i,j]]]), \n",
    "                    d, mean, covariance)\n",
    "        return x1, x2, pdf  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "42ffdaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def creating_distributions(mean1, mean2, covar, d,count):\n",
    "        \"\"\"makes things pretty - create illustrations of multiple gaussian distributions\n",
    "        TODO- Change the graph size\"\"\"\n",
    "        bidimentional_mean = np.matrix([[mean1], [mean2]])  # Mean\n",
    "        bidimentional_covariance = np.matrix([\n",
    "        [covar, 0.], \n",
    "        [0., covar]])  # Covariance\n",
    "        x1, x2, p = generate_surface(\n",
    "            bidimentional_mean, bidimentional_covariance, d)\n",
    "\n",
    "        fig, axs = plt.subplots(nrows=1, ncols=1, figsize=(20,10))\n",
    "        con = axs.contourf(x1, x2, p, 33, cmap=cm.YlGnBu)\n",
    "        axs.set_xlabel('$x_1$', fontsize=10)\n",
    "        axs.set_ylabel('$x_2$', fontsize=10)\n",
    "        axs.axis([-50, 50, -50, 50])\n",
    "        axs.set_aspect('equal')\n",
    "        axs.set_title('Distribution', fontsize=13)\n",
    "\n",
    "        # Add colorbar and title\n",
    "        fig.subplots_adjust(right=0.8)\n",
    "        cbar_ax = fig.add_axes([0.85, 0.15, 0.02, 0.7])\n",
    "        cbar = fig.colorbar(con, cax=cbar_ax)\n",
    "        cbar.ax.set_ylabel('$p(x_1, x_2)$', fontsize=10)\n",
    "        #plt.show()\n",
    "        return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "de32a264",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def setting_mean_covariance():\n",
    "        \"\"\"generates multiple gaussian distributions/classes\"\"\"\n",
    "        d=2\n",
    "        with open ('GaussClasses.csv', mode='w') as Random_Gauss_Distributions:\n",
    "            fieldnames = ['Mean1','Mean2', 'Covariance']\n",
    "            writer=csv.DictWriter(Random_Gauss_Distributions,fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "\n",
    "            for i in range (numClasses):\n",
    "                temp1 = random.gauss(minRange, maxRange) #First mean\n",
    "                str_temp1=str(temp1)\n",
    "\n",
    "                temp2 = random.gauss(minRange, maxRange) #second mean\n",
    "                str_temp2=str(temp2)\n",
    "\n",
    "                temp3 = random.gauss(MinRange, maxRange) #covariance\n",
    "                str_temp3=str(temp2)\n",
    "\n",
    "                writer.writerow({'Mean1':str_temp1,'Mean2':str_temp2,'Covariance':str_temp3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "683426cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def read_distributions():\n",
    "        \"\"\"\n",
    "        Reads all the generted Gaussian distributions and \n",
    "        calls the creating_distributions function tto make illustrations for each distribution \n",
    "        \"\"\"\n",
    "        d=2\n",
    "        with open ('GaussClasses.csv', mode='r') as Random_Gauss_Distributions:\n",
    "            csv_reader=csv.DictReader(Random_Gauss_Distributions)\n",
    "\n",
    "            linecount=0\n",
    "            pp = PdfPages('Save multiple plots as PDF.pdf')\n",
    "\n",
    "            for row in csv_reader:\n",
    "\n",
    "                if linecount == 0:\n",
    "                    linecount+=1\n",
    "                #elif linecount == 1:\n",
    "                   # print(row['Mean1'])\n",
    "                    #linecount+=1\n",
    "                else:\n",
    "                    #print(row['Mean1'])\n",
    "                    print(linecount)\n",
    "\n",
    "                    figure = creating_distributions(float(row['Mean1']), float(row['Mean2']),float(row['Covariance']), d,line_count)\n",
    "                    pp.savefig(figure)\n",
    "                    linecount+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "6b33e4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #distance of each class with the other\n",
    "    def euclidean_distance(a,b):\n",
    "        dist = np.linalg.norm(a - b)\n",
    "        return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "563db9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #Creating a csv file\n",
    "    def datasetOfPoints():\n",
    "        \"\"\"Creates random popints that ned to be classified into classes\"\"\"\n",
    "        with open('PointsToBeClassified.csv', mode='w') as dist_write:\n",
    "            feildnames = ['X','Y']\n",
    "            writer = csv.DictWriter(dist_write, fieldnames = feildnames)\n",
    "            writer.writeheader()\n",
    "            for i in range (1,501):\n",
    "                writer.writerow({'X':random.uniform(minRage, maxRange), 'Y':random.uniform(minRange, maxRange)})\n",
    "\n",
    "        #find centers of each class\n",
    "        lists=[]\n",
    "        with open ('DataSet.csv', mode='r') as data_read:\n",
    "            reader = csv.DictReader(data_read)\n",
    "            list_count = 0\n",
    "            for row in reader:\n",
    "                if list_count == 0:\n",
    "                    list_count+=1\n",
    "                else:\n",
    "                    lists.append(return_center(float(row['Mean1']), float(row['Mean2']), float(row['Covariance'])))\n",
    "                    list_count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "fce26f54",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataSets' object has no attribute 'setting_mean_covariance'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-136-d530c3948a7c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-136-d530c3948a7c>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m#creating all the datasets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataSets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100.95\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetting_mean_covariance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_distributions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasetOfPoints\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataSets' object has no attribute 'setting_mean_covariance'"
     ]
    }
   ],
   "source": [
    "\n",
    "    #x = float(input(\"Enter the x: \"))\n",
    "   # y = float(input(\"Enter the y: \"))\n",
    "\n",
    "    #setting_mean_covariance()\n",
    "    #creating_distributions(0,0,2.2,2)\n",
    "    #generate_surface([[0.],[0.]],[[2.2,0.],[0,2.2]],2)\n",
    "    #read_dis()\n",
    "    \n",
    "def main():\n",
    "    #creating all the datasets\n",
    "        obj = DataSets(50, 10, 2.5, 100.95)\n",
    "        obj.setting_mean_covariance()\n",
    "        obj.read_distributions()\n",
    "        obj.datasetOfPoints()\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "            main()\n",
    "\n",
    "\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4fc805",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
