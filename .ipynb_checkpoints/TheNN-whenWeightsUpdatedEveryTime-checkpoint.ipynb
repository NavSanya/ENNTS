{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1797d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Input, Dense, Dropout, Embedding, LSTM, Flatten\n",
    "from keras.models import Model\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a4621e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a761e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Onehot2Int(object):\n",
    "    \"\"\"To plot the decision boundary\"\"\"\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred = self.model.predict(X)\n",
    "        return np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadfb2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def theOriginalNN(X,Y):\n",
    "    \"\"\"\n",
    "    The NN model which we will train and get the weights for the new\n",
    "    NN model\n",
    "    \"\"\"    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3)\n",
    "    \n",
    "\n",
    "    feature_vector_shape = len(X_train[0])\n",
    "    input_shape = (feature_vector_shape,)\n",
    "#     print(\"Input shape\",input_shape)\n",
    "#     print(f'Feature shape: {input_shape}')\n",
    "    \n",
    "    model.add(Dense(2,input_shape=input_shape, activation = 'relu'))\n",
    "    #model.add(Dense(16, activation = 'relu'))\n",
    "    model.add(Dense(4, activation = 'relu'))\n",
    "    model.add(Dense(2, activation='softmax'))  \n",
    "\n",
    "\n",
    " \n",
    "    es = [EarlyStopping(monitor='loss', mode='min', verbose=0, patience=50)]\n",
    "\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer= \"adam\", metrics=['accuracy'])\n",
    "   \n",
    "\n",
    "     #print(\"Weights and biases of the layers before training the model: \\n\")\n",
    "#     a=[]\n",
    "#     for layer in model.layers:\n",
    "# #         print(layer.name)\n",
    "# #         print(\"Weights\")\n",
    "# #         print(\"Shape: \",layer.get_weights()[0].shape,'\\n',layer.get_weights()[0])\n",
    "#             a=np.append(layer.get_weights()[0])\n",
    "#         print(\"Bias\")\n",
    "#         print(\"Shape: \",layer.get_weights()[1].shape,'\\n',layer.get_weights()[1],'\\n')\n",
    "\n",
    "#     print(X_train.shape,Y_train.shape)\n",
    "#     print(X_test.shape, Y_test.shape)\n",
    "    Y_tt = Y_test\n",
    "    Y_tr = Y_train\n",
    "    Y_train = to_categorical(Y_train)\n",
    "#     print(Y_train.shape)\n",
    "    Y_test = to_categorical(Y_test)\n",
    "    \n",
    "   \n",
    "    e = 500   #The number of epochs\n",
    "    obj = model.fit(X_train, Y_train, shuffle = True, verbose=0, callbacks=es)\n",
    "    \n",
    "#     print(\"Weights and biases of the layers after training the model: \\n\")\n",
    "#     for layer in model.layers:\n",
    "#         print(layer.name)\n",
    "#         print(\"Weights\")\n",
    "#         print(\"Shape: \",layer.get_weights()[0].shape,'\\n',layer.get_weights()[0])\n",
    "#         print(\"Bias\")\n",
    "#         print(\"Shape: \",layer.get_weights()[1].shape,'\\n',layer.get_weights()[1],'\\n')\n",
    "        \n",
    "    #predict\n",
    "    # pred = model.predict(X_train)\n",
    "    # print(\"After Prediction of model\", pred)\n",
    "   \n",
    "    \n",
    "    scores = model.evaluate(X_test, Y_test)\n",
    "    Loss = np.array(obj.history[\"loss\"])\n",
    "    Epoch = np.arange(e)\n",
    "    Accuracy = np.array(obj.history[\"accuracy\"])\n",
    "    #print(Loss, Epoch, Accuracy)\n",
    "    \n",
    "    graph_it(Loss, Epoch, Accuracy, model,scores,X_train, X_test, Y_train, Y_test, Y_tt)\n",
    "\n",
    "#     weights = model.layers[0].get_weights()[0]\n",
    "#     biases = model.layers[0].get_weights()[1]\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ac75a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_it(Loss, Epoch, Accuracy,scores,X_train, X_test, Y_train, Y_test,Y_tt):\n",
    "    \"\"\"\n",
    "    Creating all the graphs:\n",
    "    1. Loss vs Epoch\n",
    "    2. Accuracy vs Epoch\n",
    "    3. The decision boundarys\n",
    "    \"\"\"\n",
    "    \n",
    "    plt.figure(figsize=(10,7))\n",
    "    plt.plot(Epoch, Loss)\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"The LOSS Graph\")\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(10,7))\n",
    "    plt.plot(Epoch, Accuracy)\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(\"The ACCURACY graph\")\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    print(f'Test results - Loss: {scores[0]} - Accuracy: {scores[1]*100}%')\n",
    "    \n",
    "    # Plot decision boundary\n",
    "    keras_model_no_ohe = Onehot2Int(model)\n",
    "\n",
    "    # Plot decision boundary\n",
    "    \n",
    "    plt.figure(figsize=(10,7))\n",
    "    plot_decision_regions(X_test, Y_tt, clf=keras_model_no_ohe, legend=2)\n",
    "    plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161182ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def theNewNN(X,Y):\n",
    "    \"\"\"\n",
    "    The NN model which will be trained by the weights \n",
    "    we got by the OriginalNN()\n",
    "    \"\"\"\n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3)\n",
    "\n",
    "    # es = EarlyStopping(monitor='loss', mode='min', verbose=0, patience=50)\n",
    "\n",
    "    # model.compile(loss=\"categorical_crossentropy\", optimizer= \"adam\", metrics=['accuracy'])\n",
    "    \n",
    "#     print(X_train.shape,Y_train.shape)\n",
    "#     print(X_test.shape, Y_test.shape)\n",
    "    Y_tt = Y_test\n",
    "    Y_train = to_categorical(Y_train)\n",
    "#     print(Y_train.shape)\n",
    "    Y_test = to_categorical(Y_test)\n",
    "    \n",
    "\n",
    "    \n",
    "    # Setting new weights and biases\n",
    "    # for layer in model.layers:\n",
    "    #     a,b = layer.get_weights()[0].shape\n",
    "    #     layer.set_weights([np.random.randn(a,b), np.ones(layer.get_weights()[1].shape)])\n",
    "    a=[]\n",
    "\n",
    "#     print(\"Weights and biases of the layers after setting the new weights and biases: \\n\")\n",
    "    for layer in model.layers:\n",
    "        a=np.append(a,layer.get_weights()[0])\n",
    "        \n",
    "    es = [EarlyStopping(monitor='loss', mode='min', verbose=0, patience=50)]\n",
    "\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer= \"adam\", metrics=['accuracy'], loss_weights = a)\n",
    "\n",
    "#         print(layer.name)\n",
    "#         print(\"Weights\")\n",
    "#         print(\"Shape: \",layer.get_weights()[0].shape,'\\n',layer.get_weights()[0])\n",
    "#         print(\"Bias\")\n",
    "#         print(\"Shape: \",layer.get_weights()[1].shape,'\\n',layer.get_weights()[1],'\\n')\n",
    "   \n",
    "    e = 500   #The number of epochs\n",
    "    obj = model.fit(X_train, Y_train, shuffle = True, verbose=0, callbacks=es)\n",
    "    \n",
    "#     print(\"Weights and biases of the layers after setting the new weights and biases: \\n\")\n",
    "#     for layer in model.layers:\n",
    "#         print(layer.name)\n",
    "#         print(\"Weights\")\n",
    "#         print(\"Shape: \",layer.get_weights()[0].shape,'\\n',layer.get_weights()[0])\n",
    "#     print(\"Bias\")\n",
    "#     print(\"Shape: \",layer.get_weights()[1].shape,'\\n',layer.get_weights()[1],'\\n')\n",
    "    \n",
    "    \n",
    "    #predict\n",
    "    pred = model.predict(X_train)\n",
    "    print(\"After Prediction of model\", pred)\n",
    "    \n",
    "    scores = model.evaluate(X_test, Y_test)\n",
    "    L = np.array(obj.history[\"loss\"])\n",
    "    E = np.arange(e)\n",
    "    A = np.array(obj.history[\"accuracy\"])\n",
    "    #print(Loss, Epoch, Accuracy)\n",
    "    graph_it(L, E, A,scores,X_train, X_test, Y_train, Y_test, Y_tt)\n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985e4fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Old Dataset\n",
    "def OldDataset():\n",
    "    \"\"\"\n",
    "    The dataset for the original model\n",
    "    \"\"\"\n",
    "    #Class 1\n",
    "    mean = [5,5]\n",
    "    cov = [[10,0],\n",
    "           [0,10]] \n",
    "    Class1 = np.random.multivariate_normal(mean,cov,1000)\n",
    "\n",
    "    #Class 2\n",
    "    mean = [-5,5]\n",
    "    cov = [[10,0],\n",
    "           [0,10]] \n",
    "    Class2 = np.random.multivariate_normal(mean,cov,1000)    \n",
    "    \n",
    "\n",
    "    X = np.vstack([Class1, Class2])\n",
    "\n",
    "    # Y = np.array([0]*500 + [1]*500 + [2]*500)\n",
    "    Y = np.array([0]*1000 + [1]*1000)\n",
    "    #print(Y)\n",
    "    \n",
    "    plt.figure(figsize=(10,7))\n",
    "    plt.scatter(X[:,0], X[:,1], c=Y, cmap='plasma', s=100, alpha=0.5)\n",
    "    plt.show()\n",
    "    \n",
    "    theOriginalNN(X,Y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af43aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#New Dataset\n",
    "def NewDataset(i):\n",
    "    \"\"\"\n",
    "    The dataset for the new model\n",
    "    \"\"\"\n",
    "    #Class 3\n",
    "    mean = [i,i]\n",
    "    cov = [[10,0],\n",
    "           [0,10]] \n",
    "    Class3 = np.random.multivariate_normal(mean,cov,1000)\n",
    "\n",
    "    #Class 4\n",
    "    mean = [(-i),i]\n",
    "    cov = [[10,0],\n",
    "           [0,10]] \n",
    "    Class4 = np.random.multivariate_normal(mean,cov,1000)\n",
    "    \n",
    "    X = np.vstack([Class3, Class4])\n",
    "\n",
    "    # Y = np.array([0]*500 + [1]*500 + [2]*500)\n",
    "    Y = np.array([0]*1000 + [1]*1000)\n",
    "    #print(Y)\n",
    "\n",
    "    plt.figure(figsize=(10,7))\n",
    "    plt.scatter(X[:,0], X[:,1], c=Y, cmap='plasma', s=100, alpha=0.5)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "    theNewNN(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d14662",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    print(\"****************************The Original NN*************************************\")\n",
    "    OldDataset()\n",
    "    # for i in range (1,10): \n",
    "    #     print(\"\\n**************************The \",i,\" NN************************************\")\n",
    "    #     NewDataset(i)\n",
    "    \n",
    "    print(\"****************************THE NEW NN**********************************\")\n",
    "    NewDataset(4)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a247e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
